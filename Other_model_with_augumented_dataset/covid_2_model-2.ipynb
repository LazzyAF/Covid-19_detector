{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "                    rescale = 1./255,\n",
    "                                       \n",
    ")\n",
    "\n",
    "val_datagen = image.ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1146 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "  'CovidDataset/Train',\n",
    "    target_size = (244,244),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "##validation data generator\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "  'CovidDataset/Val',\n",
    "    target_size = (244,244),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 242, 242, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 240, 240, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 118, 118, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 59, 59, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 59, 59, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 57, 57, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                6422592   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,663,489\n",
      "Trainable params: 6,663,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN based Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', input_shape = (244,244,3)))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss = tf.keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "8/8 [==============================] - 152s 19s/step - loss: 1.0861 - accuracy: 0.5039 - val_loss: 0.6670 - val_accuracy: 0.5938\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 151s 19s/step - loss: 0.5748 - accuracy: 0.7109 - val_loss: 0.4194 - val_accuracy: 0.7969\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 138s 17s/step - loss: 0.3983 - accuracy: 0.8477 - val_loss: 0.1749 - val_accuracy: 0.9531\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 96s 12s/step - loss: 0.2230 - accuracy: 0.9297 - val_loss: 0.2157 - val_accuracy: 0.9531\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 107s 13s/step - loss: 0.2885 - accuracy: 0.8828 - val_loss: 0.1723 - val_accuracy: 0.9062\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 115s 14s/step - loss: 0.2578 - accuracy: 0.9102 - val_loss: 0.2467 - val_accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_generator, steps_per_epoch = 8, epochs = 6, validation_data = val_generator, validation_steps = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-895f6bf77986>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"./CovidDataset/Test/Normal/\"):\n",
    "    img = image.load_img(\"./CovidDataset/Test/Normal/\"+i, target_size = (244,244))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    p = model.predict_classes(img)\n",
    "    y_test.append(p[0,0])\n",
    "    y_actual.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(\"./CovidDataset/Test/Covid/\"):\n",
    "    img = image.load_img(\"./CovidDataset/Test/Covid/\"+i, target_size = (244,244))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    p = model.predict_classes(img)\n",
    "    y_test.append(p[0,0])\n",
    "    y_actual.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = np.array(y_actual)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_actual, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm ,cmap='plasma', annot = True)\n",
    "# y axis - actual\n",
    "# x axis - precidted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883116883116883\n"
     ]
    }
   ],
   "source": [
    "#precision = 0.78\n",
    "#recall = 1\n",
    "f1_score = f1_score(y_actual, y_test,labels=None, pos_label=1, average='binary')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
